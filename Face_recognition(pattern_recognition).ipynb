{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face recognition(pattern recognition).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQ_v7QLVHzLE"
      },
      "source": [
        "kaggle data upload\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "doZflxhnlB-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31584fa-f9f8-469e-e54b-4b75152d1076"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.flush_and_unmount()\n",
        "drive.mount(\"/content/gdrive\")\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OR6MCKDtlxZQ",
        "outputId": "7a03a5fe-53a1-432f-9cac-9f460d8103e3"
      },
      "source": [
        "!ln -s /content/gdrive/My\\ Drive/ /mydrive\n",
        "!ls /mydrive"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " black\t\t DB_login\t        Lab4OS_video.mp4   Pagination\n",
            " Classroom\t Europass\t        LAB5OS_5845\n",
            " dataset\t'Getting started.pdf'  'My Drive'\n",
            "'dataset test'\t Hw\t\t       'national id.pdf'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaP0foDYQVPj"
      },
      "source": [
        "Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1-4sj7Z5WWd",
        "outputId": "63a89fcd-4b50-46e6-a5f7-340d95b3ffd7"
      },
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "choice=int(input(\"Enter your choice: ( 0: 50% split face Recognition\\t1: 70% split face recogntion\\t2: Faces vs non-faces ) : \"))\n",
        "divider=0\n",
        "multiplier=1\n",
        "if choice==0 : \n",
        "  divider=5 \n",
        "elif choice==2:\n",
        "  divider=5 \n",
        "  multiplier=2\n",
        "elif choice==1 :\n",
        "  divider=7\n",
        "\n",
        "if choice!=2:\n",
        "  dataset=[]\n",
        "  testdata=[]\n",
        "  traindata=[]\n",
        "  labels = []\n",
        "  c=[]\n",
        "  k=1\n",
        "  img2=[]\n",
        "  for i in range(40):\n",
        "    imgarray=[]\n",
        "    for j in range(10):\n",
        "      if j<divider:     #labels per class for train data\n",
        "        labels.append(i+1)\n",
        "      img = plt.imread(f'/mydrive/dataset test/{k}_{i+1}.jpg')\n",
        "      img2=cv2.resize(img,(92,112))\n",
        "      npimg=np.array(img2)\n",
        "      imgarray.append(npimg)\n",
        "      k=k+1\n",
        "    dataset.append(imgarray)\n",
        "      \n",
        "  plt.imshow(img2)\n",
        "\n",
        "  dataset=np.asarray(dataset)\n",
        "  labels = np.asarray(labels)\n",
        "  print(np.shape(dataset))\n",
        "\n",
        "  if choice==0:\n",
        "    for i in range(10):\n",
        "      if i%2==0:\n",
        "        traindata.append(dataset[:,i])\n",
        "      else:\n",
        "        testdata.append(dataset[:,i])\n",
        "  else:\n",
        "    for i in range(7):\n",
        "        traindata.append(dataset[:,i])\n",
        "    for i in range(3):\n",
        "        testdata.append(dataset[:,i+7])\n",
        "\n",
        "  traindata=np.asarray(traindata)\n",
        "  traindata1=traindata.transpose(1,0,2,3)\n",
        "  #plt.imshow(traindata[1,0,:])\n",
        "\n",
        "  testdata=np.asarray(testdata)\n",
        "  testdata1=testdata.transpose(1,0,2,3)\n",
        "  plt.imshow(testdata1[2,1,:])\n",
        "\n",
        "  print(np.shape(traindata1))\n",
        "  print(multiplier)\n",
        "  print(divider)\n",
        "\n",
        "elif choice==2:\n",
        "\n",
        "  #faces vs non-faces\n",
        "  dataset=[]\n",
        "  testdata=[]\n",
        "  traindata=[]\n",
        "  labels = []\n",
        "  c=[]\n",
        "  k=1\n",
        "  img2=[]\n",
        "  for i in range(40):\n",
        "    imgarray=[]\n",
        "    for j in range(10):\n",
        "      if j<5:\n",
        "        labels.append(1)\n",
        "      img = plt.imread(f'/mydrive/dataset test/{k}_{i+1}.jpg')\n",
        "      img2=cv2.resize(img,(92,112))\n",
        "      npimg=np.array(img2)\n",
        "\n",
        "      imgarray.append(npimg)\n",
        "      k=k+1\n",
        "    dataset.append(imgarray)\n",
        "  for i in range(40):\n",
        "    imgarray=[]\n",
        "    for j in range(10):\n",
        "      img=[]\n",
        "      if j<5:\n",
        "        labels.append(2)\n",
        "      if i<10:  \n",
        "        img = plt.imread(f'/mydrive/black/00{i}{j}.jpg')\n",
        "      else:\n",
        "        img = plt.imread(f'/mydrive/black/0{i}{j}.jpg')\n",
        "        \n",
        "      img2=np.resize(img,(92,112))\n",
        "      npimg=np.array(img2)\n",
        "      npimg=npimg.T\n",
        "      imgarray.append(npimg)\n",
        "      k=k+1\n",
        "    dataset.append(imgarray)\n",
        "\n",
        "\n",
        "  dataset=np.asarray(dataset)\n",
        "  labels = np.asarray(labels)\n",
        "  print(\"shape after non faces : \", np.shape(dataset))\n",
        "\n",
        "  for i in range(10):\n",
        "      if i%2==0:\n",
        "        traindata.append(dataset[:,i])\n",
        "      else:\n",
        "        testdata.append(dataset[:,i])  \n",
        "  \n",
        "\n",
        "\n",
        "      \n",
        "\n",
        "  dataset=np.asarray(dataset)\n",
        "  labels = np.asarray(labels)\n",
        "  traindata=np.asarray(traindata)\n",
        "  traindata1=traindata.transpose(1,0,2,3)\n",
        "  testdata=np.asarray(testdata)\n",
        "  testdata1=testdata.transpose(1,0,2,3)  \n",
        "  print(np.shape(traindata1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter your choice: ( 0: 50% split face Recognition\t1: 70% split face recogntion\t2: Faces vs non-faces ) : 2\n",
            "shape after non faces :  (80, 10, 112, 92)\n",
            "(80, 5, 112, 92)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyvmKA8oQjNL"
      },
      "source": [
        "PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGFQ-S5Y5ePU",
        "outputId": "1389ded3-6249-4909-f19e-2b955e5ab984"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "eigenvectors=[]\n",
        "meanMatrix=[]\n",
        "temp=[]\n",
        "centralized=[]\n",
        "listPCA1=[]\n",
        "listPCA2=[]\n",
        "listPCA3=[]\n",
        "listPCA4=[]\n",
        "traindata1 = traindata1.reshape(40*divider*multiplier,10304)\n",
        "print(np.shape(traindata1))\n",
        "meanMatrix = np.mean(traindata1,axis=0)\n",
        "print(np.shape(meanMatrix))\n",
        "centralized = traindata1 - meanMatrix\n",
        "print('centralized')\n",
        "print(np.shape(centralized))\n",
        "covMatrix = np.cov(centralized.transpose())\n",
        "print('cov')\n",
        "print(np.shape(covMatrix))\n",
        "eigenValues,eigenVectors=np.linalg.eig(covMatrix)\n",
        "sortedEigenValues=np.argsort(eigenValues)\n",
        "eigenSum=np.sum(eigenValues)\n",
        "eigenAlpha=0\n",
        "for i in range(len(eigenValues)):\n",
        "  eigenAlpha=eigenAlpha+eigenValues[sortedEigenValues[-i-1]]\n",
        "  alpha=eigenAlpha/eigenSum\n",
        "  if alpha<=0.8:\n",
        "    listPCA1.append(eigenVectors[:,i])\n",
        "  elif alpha<=0.85:\n",
        "    listPCA2.append(eigenVectors[:,i])\n",
        "  elif alpha<=0.9:\n",
        "    listPCA3.append(eigenVectors[:,i])\n",
        "  elif alpha<=0.95:\n",
        "    listPCA4.append(eigenVectors[:,i])\n",
        "\n",
        "    \n",
        "print(np.shape(listPCA1))\n",
        "print(np.shape(listPCA2))\n",
        "print(np.shape(listPCA3))\n",
        "print(np.shape(listPCA4))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200, 10304)\n",
            "(10304,)\n",
            "centralized\n",
            "(200, 10304)\n",
            "cov\n",
            "(10304, 10304)\n",
            "(25, 10304)\n",
            "(11, 10304)\n",
            "(19, 10304)\n",
            "(36, 10304)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oj9R0qs45lR7"
      },
      "source": [
        "Data Projection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjNcY9nUc55u"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "testdata1 = testdata1.reshape(40*(10-divider)*multiplier,10304)\n",
        "\n",
        "listPCA1=np.asarray(listPCA1)\n",
        "listPCA2=np.asarray(listPCA2)\n",
        "listPCA3=np.asarray(listPCA3)\n",
        "listPCA4=np.asarray(listPCA4)\n",
        "dataProjection1=np.dot(listPCA1,traindata1.T)\n",
        "dataProjection2=np.dot(listPCA2,traindata1.T)\n",
        "dataProjection3=np.dot(listPCA3,traindata1.T)\n",
        "dataProjection4=np.dot(listPCA4,traindata1.T)\n",
        "\n",
        "dataProjection1=np.real(dataProjection1.transpose())\n",
        "dataProjection2=np.real(dataProjection2.transpose())\n",
        "dataProjection3=np.real(dataProjection3.transpose())\n",
        "dataProjection4=np.real(dataProjection4.transpose())\n",
        "\n",
        "testProjection1=np.dot(listPCA1,testdata1.T)\n",
        "testProjection2=np.dot(listPCA2,testdata1.T)\n",
        "testProjection3=np.dot(listPCA3,testdata1.T)\n",
        "testProjection4=np.dot(listPCA4,testdata1.T)\n",
        "\n",
        "testProjection1=np.real(testProjection1.transpose())\n",
        "testProjection2=np.real(testProjection2.transpose())\n",
        "testProjection3=np.real(testProjection3.transpose())\n",
        "testProjection4=np.real(testProjection4.transpose())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwH8QhIg5yk7"
      },
      "source": [
        "Classify Data to nearest first neighbor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VV-1pLuo5vGR",
        "outputId": "a5655ec8-e258-472d-d517-b21f18b212d9"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "# scaler.fit(dataProjection1)\n",
        "# scaledData1=scaler.transform(dataProjection1)\n",
        "classifier1=KNeighborsClassifier(n_neighbors=1)\n",
        "classifier2=KNeighborsClassifier(n_neighbors=1)\n",
        "classifier3=KNeighborsClassifier(n_neighbors=1)\n",
        "classifier4=KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "classifier1.fit(dataProjection1,labels)\n",
        "classifier2.fit(dataProjection2,labels)\n",
        "classifier3.fit(dataProjection3,labels)\n",
        "classifier4.fit(dataProjection4,labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8De0WgJj6Ofx"
      },
      "source": [
        "PCA Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9e7Pi9xW6QE_"
      },
      "source": [
        "labelsPrediction1=classifier1.predict(testProjection1)\n",
        "labelsPrediction2=classifier2.predict(testProjection2)\n",
        "labelsPrediction3=classifier3.predict(testProjection3)\n",
        "labelsPrediction4=classifier4.predict(testProjection4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybVfGgLA6TEA"
      },
      "source": [
        "PCA Classification report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QknQJnaD6VtY",
        "outputId": "19c3ad88-0374-4e1d-c048-d95ad742ed34"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "print(\"With alpha = 0.8\")\n",
        "print(classification_report(labels,labelsPrediction1))\n",
        "print(confusion_matrix(labels,labelsPrediction1))\n",
        "\n",
        "print(\"With alpha = 0.85\")\n",
        "print(classification_report(labels,labelsPrediction2))\n",
        "print(confusion_matrix(labels,labelsPrediction2))\n",
        "\n",
        "print(\"With alpha = 0.9\")\n",
        "print(classification_report(labels,labelsPrediction3))\n",
        "print(confusion_matrix(labels,labelsPrediction3))\n",
        "\n",
        "print(\"With alpha = 0.95\")\n",
        "print(classification_report(labels,labelsPrediction4))\n",
        "print(confusion_matrix(labels,labelsPrediction4))\n",
        "print(\"\\n\\n\\n*** it is noticable that the accuracy increases when alpha increases (inversely proptional)***\\n\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "With alpha = 0.8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         5\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00         5\n",
            "           4       1.00      1.00      1.00         5\n",
            "           5       0.57      0.80      0.67         5\n",
            "           6       1.00      1.00      1.00         5\n",
            "           7       1.00      1.00      1.00         5\n",
            "           8       0.83      1.00      0.91         5\n",
            "           9       1.00      1.00      1.00         5\n",
            "          10       1.00      0.80      0.89         5\n",
            "          11       1.00      1.00      1.00         5\n",
            "          12       1.00      1.00      1.00         5\n",
            "          13       1.00      1.00      1.00         5\n",
            "          14       1.00      1.00      1.00         5\n",
            "          15       0.83      1.00      0.91         5\n",
            "          16       1.00      1.00      1.00         5\n",
            "          17       1.00      1.00      1.00         5\n",
            "          18       1.00      1.00      1.00         5\n",
            "          19       1.00      1.00      1.00         5\n",
            "          20       1.00      0.80      0.89         5\n",
            "          21       0.71      1.00      0.83         5\n",
            "          22       1.00      1.00      1.00         5\n",
            "          23       1.00      0.60      0.75         5\n",
            "          24       1.00      1.00      1.00         5\n",
            "          25       0.71      1.00      0.83         5\n",
            "          26       1.00      1.00      1.00         5\n",
            "          27       1.00      1.00      1.00         5\n",
            "          28       1.00      0.80      0.89         5\n",
            "          29       0.83      1.00      0.91         5\n",
            "          30       1.00      1.00      1.00         5\n",
            "          31       1.00      1.00      1.00         5\n",
            "          32       1.00      1.00      1.00         5\n",
            "          33       1.00      1.00      1.00         5\n",
            "          34       1.00      1.00      1.00         5\n",
            "          35       1.00      0.40      0.57         5\n",
            "          36       1.00      1.00      1.00         5\n",
            "          37       0.83      1.00      0.91         5\n",
            "          38       1.00      1.00      1.00         5\n",
            "          39       1.00      1.00      1.00         5\n",
            "          40       0.67      0.40      0.50         5\n",
            "\n",
            "    accuracy                           0.94       200\n",
            "   macro avg       0.95      0.94      0.94       200\n",
            "weighted avg       0.95      0.94      0.94       200\n",
            "\n",
            "[[5 0 0 ... 0 0 0]\n",
            " [0 5 0 ... 0 0 0]\n",
            " [0 0 5 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 5 0 0]\n",
            " [0 0 0 ... 0 5 0]\n",
            " [0 0 0 ... 0 0 2]]\n",
            "With alpha = 0.85\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.60      0.60      0.60         5\n",
            "           2       1.00      0.80      0.89         5\n",
            "           3       0.60      0.60      0.60         5\n",
            "           4       0.43      0.60      0.50         5\n",
            "           5       0.33      0.60      0.43         5\n",
            "           6       0.31      1.00      0.48         5\n",
            "           7       0.50      0.40      0.44         5\n",
            "           8       0.62      1.00      0.77         5\n",
            "           9       0.50      0.80      0.62         5\n",
            "          10       0.00      0.00      0.00         5\n",
            "          11       0.60      0.60      0.60         5\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       0.75      0.60      0.67         5\n",
            "          14       1.00      0.80      0.89         5\n",
            "          15       0.80      0.80      0.80         5\n",
            "          16       0.40      0.40      0.40         5\n",
            "          17       0.71      1.00      0.83         5\n",
            "          18       1.00      0.60      0.75         5\n",
            "          19       0.75      0.60      0.67         5\n",
            "          20       0.50      0.60      0.55         5\n",
            "          21       1.00      0.80      0.89         5\n",
            "          22       0.60      0.60      0.60         5\n",
            "          23       0.75      0.60      0.67         5\n",
            "          24       0.43      0.60      0.50         5\n",
            "          25       0.83      1.00      0.91         5\n",
            "          26       0.30      0.60      0.40         5\n",
            "          27       1.00      0.80      0.89         5\n",
            "          28       1.00      0.60      0.75         5\n",
            "          29       0.50      0.40      0.44         5\n",
            "          30       0.60      0.60      0.60         5\n",
            "          31       0.80      0.80      0.80         5\n",
            "          32       0.50      0.20      0.29         5\n",
            "          33       0.50      0.20      0.29         5\n",
            "          34       0.71      1.00      0.83         5\n",
            "          35       1.00      0.20      0.33         5\n",
            "          36       0.75      0.60      0.67         5\n",
            "          37       1.00      0.40      0.57         5\n",
            "          38       0.80      0.80      0.80         5\n",
            "          39       0.40      0.40      0.40         5\n",
            "          40       0.50      0.20      0.29         5\n",
            "\n",
            "    accuracy                           0.61       200\n",
            "   macro avg       0.65      0.61      0.60       200\n",
            "weighted avg       0.65      0.61      0.60       200\n",
            "\n",
            "[[3 0 0 ... 0 1 0]\n",
            " [0 4 0 ... 0 0 0]\n",
            " [0 0 3 ... 0 0 0]\n",
            " ...\n",
            " [1 0 0 ... 4 0 0]\n",
            " [0 0 0 ... 0 2 0]\n",
            " [0 0 0 ... 0 0 1]]\n",
            "With alpha = 0.9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.00      0.00      0.00         5\n",
            "           2       1.00      0.60      0.75         5\n",
            "           3       0.60      0.60      0.60         5\n",
            "           4       0.33      0.60      0.43         5\n",
            "           5       0.36      0.80      0.50         5\n",
            "           6       0.40      0.80      0.53         5\n",
            "           7       0.29      0.40      0.33         5\n",
            "           8       0.45      1.00      0.62         5\n",
            "           9       1.00      0.20      0.33         5\n",
            "          10       1.00      0.20      0.33         5\n",
            "          11       0.67      0.40      0.50         5\n",
            "          12       0.75      0.60      0.67         5\n",
            "          13       1.00      0.80      0.89         5\n",
            "          14       1.00      0.60      0.75         5\n",
            "          15       0.80      0.80      0.80         5\n",
            "          16       1.00      0.40      0.57         5\n",
            "          17       1.00      0.60      0.75         5\n",
            "          18       0.33      0.40      0.36         5\n",
            "          19       1.00      0.60      0.75         5\n",
            "          20       1.00      0.40      0.57         5\n",
            "          21       0.75      0.60      0.67         5\n",
            "          22       0.75      0.60      0.67         5\n",
            "          23       0.43      0.60      0.50         5\n",
            "          24       0.43      0.60      0.50         5\n",
            "          25       0.30      0.60      0.40         5\n",
            "          26       0.33      0.20      0.25         5\n",
            "          27       0.36      0.80      0.50         5\n",
            "          28       1.00      0.40      0.57         5\n",
            "          29       1.00      0.60      0.75         5\n",
            "          30       0.31      1.00      0.48         5\n",
            "          31       1.00      0.60      0.75         5\n",
            "          32       1.00      0.40      0.57         5\n",
            "          33       0.75      0.60      0.67         5\n",
            "          34       0.83      1.00      0.91         5\n",
            "          35       0.60      0.60      0.60         5\n",
            "          36       1.00      0.40      0.57         5\n",
            "          37       0.67      0.40      0.50         5\n",
            "          38       0.50      0.60      0.55         5\n",
            "          39       0.25      0.40      0.31         5\n",
            "          40       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.55       200\n",
            "   macro avg       0.66      0.55      0.54       200\n",
            "weighted avg       0.66      0.55      0.54       200\n",
            "\n",
            "[[0 0 0 ... 1 0 0]\n",
            " [0 3 0 ... 0 0 1]\n",
            " [0 0 3 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 3 0 0]\n",
            " [0 0 0 ... 0 2 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "With alpha = 0.95\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.50      0.20      0.29         5\n",
            "           2       0.67      0.40      0.50         5\n",
            "           3       1.00      0.60      0.75         5\n",
            "           4       0.22      0.80      0.35         5\n",
            "           5       0.25      0.80      0.38         5\n",
            "           6       0.67      0.40      0.50         5\n",
            "           7       0.44      0.80      0.57         5\n",
            "           8       0.67      0.80      0.73         5\n",
            "           9       0.15      0.40      0.22         5\n",
            "          10       1.00      0.20      0.33         5\n",
            "          11       1.00      0.20      0.33         5\n",
            "          12       0.00      0.00      0.00         5\n",
            "          13       1.00      0.80      0.89         5\n",
            "          14       1.00      0.40      0.57         5\n",
            "          15       0.80      0.80      0.80         5\n",
            "          16       1.00      0.20      0.33         5\n",
            "          17       1.00      0.60      0.75         5\n",
            "          18       0.25      0.20      0.22         5\n",
            "          19       1.00      0.60      0.75         5\n",
            "          20       1.00      0.20      0.33         5\n",
            "          21       0.75      0.60      0.67         5\n",
            "          22       0.29      0.80      0.42         5\n",
            "          23       0.50      0.40      0.44         5\n",
            "          24       0.20      0.20      0.20         5\n",
            "          25       0.33      0.60      0.43         5\n",
            "          26       0.50      0.40      0.44         5\n",
            "          27       0.75      0.60      0.67         5\n",
            "          28       1.00      0.40      0.57         5\n",
            "          29       0.75      0.60      0.67         5\n",
            "          30       0.57      0.80      0.67         5\n",
            "          31       0.43      0.60      0.50         5\n",
            "          32       0.33      0.20      0.25         5\n",
            "          33       0.57      0.80      0.67         5\n",
            "          34       0.75      0.60      0.67         5\n",
            "          35       0.00      0.00      0.00         5\n",
            "          36       1.00      0.20      0.33         5\n",
            "          37       0.29      0.80      0.42         5\n",
            "          38       0.71      1.00      0.83         5\n",
            "          39       0.50      0.20      0.29         5\n",
            "          40       0.00      0.00      0.00         5\n",
            "\n",
            "    accuracy                           0.48       200\n",
            "   macro avg       0.60      0.48      0.47       200\n",
            "weighted avg       0.60      0.48      0.47       200\n",
            "\n",
            "[[1 0 0 ... 0 0 0]\n",
            " [0 2 0 ... 0 0 0]\n",
            " [0 0 3 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 5 0 0]\n",
            " [0 0 0 ... 0 1 0]\n",
            " [0 0 0 ... 1 0 0]]\n",
            "\n",
            "\n",
            "\n",
            "*** it is noticable that the accuracy increases when alpha increases (inversely proptional)***\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjUMq4TXBliA"
      },
      "source": [
        "LDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "9k8_BH-WBw6_",
        "outputId": "9b2f302e-4697-4402-bf2d-ca11dc2dda45"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "instancematrix=[]\n",
        "meanMatrix=[]\n",
        "print(multiplier)\n",
        "traindata1 = traindata1.reshape(40*divider*multiplier,10304)\n",
        "testdata1 = testdata1.reshape(40*(10-divider)*multiplier,10304)\n",
        "\n",
        "if choice!=2:\n",
        "\n",
        "  for i in range(0,40*divider*multiplier,divider):\n",
        "    instancematrix=[]\n",
        "    for j in range(i,i+divider,1):\n",
        "      instancematrix.append(traindata1[i])\n",
        "      #print(np.shape(instancematrix))\n",
        "    #instancematrix=np.asarray(instancematrix)\n",
        "    temp=np.mean(instancematrix,axis = 0)\n",
        "    meanMatrix.append(temp)\n",
        "  overallMean = np.mean(traindata1,axis=0)\n",
        "  print('-------meanMatrix-------')  \n",
        "  print(np.shape(meanMatrix))\n",
        "  print(meanMatrix)\n",
        "  print('--------overallMean------')\n",
        "  print(np.shape(overallMean))\n",
        "  print(overallMean)\n",
        "  #between-class scatter matrix\n",
        "  meanMatrix = np.asarray(meanMatrix)\n",
        "  overallMean = np.asarray(overallMean)\n",
        "  meanMatrix = meanMatrix.reshape(40*multiplier,10304,1)\n",
        "  overallMean = overallMean.reshape(10304,1)\n",
        "  print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
        "  print(np.shape(meanMatrix))\n",
        "  print(np.shape(overallMean))\n",
        "  print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
        "  betweenClassScatter=np.zeros((10304,10304))\n",
        "  intsancesPerClass=5\n",
        "  if choice==1:\n",
        "    instancesPerClass=7\n",
        "  elif choice==0:\n",
        "    instancesPerClass=5  \n",
        "  for i in range(40*multiplier):\n",
        "    betweenClassScatter += instancesPerClass*(np.dot((meanMatrix[i]-overallMean),(meanMatrix[i]-overallMean).transpose()))\n",
        "    #print(i,\"           \",np.dot((meanMatrix[i]-overallMean),(meanMatrix[i]-overallMean).T))\n",
        "  print('--------')\n",
        "  print(betweenClassScatter[1000][10000])\n",
        "  print('between class scatter')\n",
        "  print(np.shape(betweenClassScatter))\n",
        "  print(betweenClassScatter)\n",
        "\n",
        "  print('finished')\n",
        "\n",
        "  withinClassScatter = np.zeros((10304,10304))\n",
        "  for i in range(0,40*divider*multiplier,divider):\n",
        "    instancematrix=[]\n",
        "    for j in range(i,i+divider,1):\n",
        "        instancematrix.append(traindata1[i])\n",
        "\n",
        "    x = meanMatrix[i%divider].reshape(10304)\n",
        "    center = instancematrix-x\n",
        "    withinClassScatter+=np.dot((center).T,center)\n",
        "  print(np.shape(withinClassScatter)) \n",
        "  print(withinClassScatter) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# faces vs non-faces \n",
        "\n",
        "\n",
        "elif choice == 2:\n",
        "\n",
        "  for i in range(0,400,200):\n",
        "    instancematrix=[]\n",
        "    for j in range(i,i+200,1):\n",
        "      instancematrix.append(traindata1[i])\n",
        "      #print(np.shape(instancematrix))\n",
        "    #instancematrix=np.asarray(instancematrix)\n",
        "    temp=np.mean(instancematrix,axis = 0)\n",
        "    meanMatrix.append(temp)\n",
        "  overallMean = np.mean(traindata1,axis=0)\n",
        "  print('-------meanMatrix-------')  \n",
        "  print(np.shape(meanMatrix))\n",
        "  print(meanMatrix)\n",
        "  print('--------overallMean------')\n",
        "  print(np.shape(overallMean))\n",
        "  print(overallMean)\n",
        "  #between-class scatter matrix\n",
        "  meanMatrix = np.asarray(meanMatrix)\n",
        "  overallMean = np.asarray(overallMean)\n",
        "  meanMatrix = meanMatrix.reshape(2,10304,1)\n",
        "  overallMean = overallMean.reshape(10304,1)\n",
        "  print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
        "  print(np.shape(meanMatrix))\n",
        "  print(np.shape(overallMean))\n",
        "  print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
        "  betweenClassScatter=np.zeros((10304,10304))\n",
        "  for i in range(2):\n",
        "    betweenClassScatter += 200*(np.dot((meanMatrix[i]-overallMean),(meanMatrix[i]-overallMean).transpose()))\n",
        "    #print(i,\"           \",np.dot((meanMatrix[i]-overallMean),(meanMatrix[i]-overallMean).T))\n",
        "  print('--------')\n",
        "  print('between class scatter')\n",
        "  print(np.shape(betweenClassScatter))\n",
        "  print(betweenClassScatter)\n",
        "\n",
        "  print('finished')\n",
        "\n",
        "  withinClassScatter = np.zeros((10304,10304))\n",
        "  for i in range(0,400,200):\n",
        "    instancematrix=[]\n",
        "    for j in range(i,i+200,1):\n",
        "        instancematrix.append(traindata1[i])\n",
        "\n",
        "    x = meanMatrix[i%divider].reshape(10304)\n",
        "    center = instancematrix-x\n",
        "    withinClassScatter+=np.dot((center).T,center)\n",
        "  print(np.shape(withinClassScatter)) \n",
        "  print(withinClassScatter)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "-------meanMatrix-------\n",
            "(2, 10304)\n",
            "[array([36., 41., 41., ..., 40., 39., 35.]), array([141., 163., 202., ..., 194., 177., 194.])]\n",
            "--------overallMean------\n",
            "(10304,)\n",
            "[107.25   122.11   133.105  ... 121.9925 103.37   107.3125]\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
            "(2, 10304, 1)\n",
            "(10304, 1)\n",
            "%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-6c73a3053ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0mbetweenClassScatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10304\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10304\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mbetweenClassScatter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moverallMean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanMatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0moverallMean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0;31m#print(i,\"           \",np.dot((meanMatrix[i]-overallMean),(meanMatrix[i]-overallMean).T))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYPscNQguBEb"
      },
      "source": [
        "LDA Eigen values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd4z93z2eZ7_"
      },
      "source": [
        "import numpy as np\n",
        "sInv = np.linalg.pinv(withinClassScatter)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQpyCejm8-6C",
        "outputId": "4410246a-12d4-42d9-a2ce-af7a18a14d90"
      },
      "source": [
        "import numpy as np\n",
        "eigenValuelda,eigenVectorlda = np.linalg.eigh(np.dot(sInv,betweenClassScatter))\n",
        "print('this is the eigenvectors')\n",
        "print(np.shape(eigenVectorlda))\n",
        "print('this is the eigenvalue')\n",
        "print(np.shape(eigenValuelda))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this is the eigenvectors\n",
            "(10304, 10304)\n",
            "this is the eigenvalue\n",
            "(10304,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sjck16D_uF9u"
      },
      "source": [
        "*LDA* data projection\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUXoHFA1l7cZ",
        "outputId": "52d07380-2df4-4681-864c-cf53f5e0aaf2"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "testdata1 = testdata1.reshape(40*(10-divider)*multiplier,10304)\n",
        "\n",
        "\n",
        "indexOfBiggestEigenvals = np.argsort(eigenValuelda)\n",
        "print(np.shape(indexOfBiggestEigenvals))\n",
        "listOfLda = []\n",
        "for index in range(39):\n",
        "  listOfLda.append(eigenVectorlda[:,indexOfBiggestEigenvals[-index-1]])\n",
        "\n",
        "LDADataProjection=np.dot(listOfLda,traindata1.T)\n",
        "LDADataProjection=np.real(LDADataProjection.T)\n",
        "\n",
        "LDATestProjection=np.dot(listOfLda,testdata1.T)\n",
        "LDATestProjection=np.real(LDATestProjection.T)\n",
        "\n",
        "print(np.shape(LDATestProjection))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10304,)\n",
            "(400, 39)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNtAjOFKuTnO"
      },
      "source": [
        "LDA classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2IdEOHLugqU",
        "outputId": "b1fbd25f-f1fe-4789-8bd0-1f7a0c4059b3"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "# scaler.fit(dataProjection1)\n",
        "# scaledData1=scaler.transform(dataProjection1)\n",
        "classifier=KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "classifier.fit(LDADataProjection,labels)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY_t3URdu4p7"
      },
      "source": [
        "LDA Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCe7upkzu6uG"
      },
      "source": [
        "LDAlabelsPrediction=classifier.predict(LDATestProjection)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXEge_gPvGU4"
      },
      "source": [
        "LDA Classification Report"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHhf1bqqvMjZ",
        "outputId": "9d448a01-da8a-494f-dd23-d02cfcbbb7d1"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"\\n\\n\\n*** LDA accuracy and confusion report***\\n\\n\\n\")\n",
        "\n",
        "print(classification_report(labels,LDAlabelsPrediction))\n",
        "print(confusion_matrix(labels,LDAlabelsPrediction))\n",
        "#print(confusion_matrix(labels,labelsPrediction1))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "*** LDA accuracy and confusion report***\n",
            "\n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.99      0.99      0.99       200\n",
            "           2       0.99      0.99      0.99       200\n",
            "\n",
            "    accuracy                           0.99       400\n",
            "   macro avg       0.99      0.99      0.99       400\n",
            "weighted avg       0.99      0.99      0.99       400\n",
            "\n",
            "[[199   1]\n",
            " [  1 199]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbh4-95nv6xp"
      },
      "source": [
        "LDA VS PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxTyuJxiwGgI",
        "outputId": "64812fc4-4dfb-4651-80fe-11873d084c31"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "\n",
        "precisionPCA1,recallPCA1,fscorePCA1,supportPCA1=score(labels,labelsPrediction1,average='macro')\n",
        "precisionPCA2,recallPCA2,fscorePCA2,supportPCA2=score(labels,labelsPrediction2,average='macro')\n",
        "precisionPCA3,recallPCA3,fscorePCA3,supportPCA3=score(labels,labelsPrediction3,average='macro')\n",
        "precisionPCA4,recallPCA4,fscorePCA4,supportPCA4=score(labels,labelsPrediction4,average='macro')\n",
        "\n",
        "precisionLDA,recallLDA,fscoreLDA,supportLDA=score(labels,LDAlabelsPrediction,average='macro')\n",
        "\n",
        "difference1=format(precisionLDA-precisionPCA1)\n",
        "difference2=format(precisionLDA-precisionPCA2)\n",
        "difference3=format(precisionLDA-precisionPCA3)\n",
        "difference4=format(precisionLDA-precisionPCA4)\n",
        "\n",
        "print(\"\\n\\ndifference in accuracy between PCA with alpha=0.8 and LDA : \",difference1)\n",
        "\n",
        "print(\"\\n\\ndifference in accuracy between PCA with alpha=0.85 and LDA : \",difference2)\n",
        "\n",
        "print(\"\\n\\ndifference in accuracy between PCA with alpha=0.9 and LDA : \",difference3)\n",
        "\n",
        "print(\"\\n\\ndifference in accuracy between PCA with alpha=0.95 and LDA : \",difference4,\"\\n\\n\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "difference in accuracy between PCA with alpha=0.8 and LDA :  0.005119047619047579\n",
            "\n",
            "\n",
            "difference in accuracy between PCA with alpha=0.85 and LDA :  0.30162202380952374\n",
            "\n",
            "\n",
            "difference in accuracy between PCA with alpha=0.9 and LDA :  0.2987729978354978\n",
            "\n",
            "\n",
            "difference in accuracy between PCA with alpha=0.96 and LDA :  0.35901098901098893 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1oCh7P6Egrv"
      },
      "source": [
        "Classification tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aviz0Q5cEmtB"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "\n",
        "classifier1=KNeighborsClassifier(n_neighbors=1)\n",
        "classifier2=KNeighborsClassifier(n_neighbors=1)\n",
        "classifier3=KNeighborsClassifier(n_neighbors=1)\n",
        "classifier4=KNeighborsClassifier(n_neighbors=1)\n",
        "classifier1.fit(dataProjection1,labels)\n",
        "classifier2.fit(dataProjection2,labels)\n",
        "classifier3.fit(dataProjection3,labels)\n",
        "classifier4.fit(dataProjection4,labels)\n",
        "labelsPrediction1=classifier1.predict(testProjection1)\n",
        "labelsPrediction2=classifier2.predict(testProjection2)\n",
        "labelsPrediction3=classifier3.predict(testProjection3)\n",
        "labelsPrediction4=classifier4.predict(testProjection4)\n",
        "\n",
        "\n",
        "\n",
        "classifier1_1=KNeighborsClassifier(n_neighbors=3)\n",
        "classifier2_1=KNeighborsClassifier(n_neighbors=3)\n",
        "classifier3_1=KNeighborsClassifier(n_neighbors=3)\n",
        "classifier4_1=KNeighborsClassifier(n_neighbors=3)\n",
        "classifier1_1.fit(dataProjection1,labels)\n",
        "classifier2_1.fit(dataProjection2,labels)\n",
        "classifier3_1.fit(dataProjection3,labels)\n",
        "classifier4_1.fit(dataProjection4,labels)\n",
        "labelsPrediction1_1=classifier1_1.predict(testProjection1)\n",
        "labelsPrediction2_1=classifier2_1.predict(testProjection2)\n",
        "labelsPrediction3_1=classifier3_1.predict(testProjection3)\n",
        "labelsPrediction4_1=classifier4_1.predict(testProjection4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classifier1_2=KNeighborsClassifier(n_neighbors=5)\n",
        "classifier2_2=KNeighborsClassifier(n_neighbors=5)\n",
        "classifier3_2=KNeighborsClassifier(n_neighbors=5)\n",
        "classifier4_2=KNeighborsClassifier(n_neighbors=5)\n",
        "classifier1_2.fit(dataProjection1,labels)\n",
        "classifier2_2.fit(dataProjection2,labels)\n",
        "classifier3_2.fit(dataProjection3,labels)\n",
        "classifier4_2.fit(dataProjection4,labels)\n",
        "labelsPrediction1_2=classifier1_2.predict(testProjection1)\n",
        "labelsPrediction2_2=classifier2_2.predict(testProjection2)\n",
        "labelsPrediction3_2=classifier3_2.predict(testProjection3)\n",
        "labelsPrediction4_2=classifier4_2.predict(testProjection4)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "classifier1_3=KNeighborsClassifier(n_neighbors=7)\n",
        "classifier2_3=KNeighborsClassifier(n_neighbors=7)\n",
        "classifier3_3=KNeighborsClassifier(n_neighbors=7)\n",
        "classifier4_3=KNeighborsClassifier(n_neighbors=7)\n",
        "classifier1_3.fit(dataProjection1,labels)\n",
        "classifier2_3.fit(dataProjection2,labels)\n",
        "classifier3_3.fit(dataProjection3,labels)\n",
        "classifier4_3.fit(dataProjection4,labels)\n",
        "labelsPrediction1_3=classifier1_3.predict(testProjection1)\n",
        "labelsPrediction2_3=classifier2_3.predict(testProjection2)\n",
        "labelsPrediction3_3=classifier3_3.predict(testProjection3)\n",
        "labelsPrediction4_3=classifier4_3.predict(testProjection4)\n",
        "\n",
        "\n",
        "\n",
        "classifierl1=KNeighborsClassifier(n_neighbors=1)\n",
        "classifierl1.fit(LDADataProjection,labels)\n",
        "LDAlabelsPredictionl1=classifierl1.predict(LDATestProjection)\n",
        "\n",
        "classifierl2=KNeighborsClassifier(n_neighbors=3)\n",
        "classifierl2.fit(LDADataProjection,labels)\n",
        "LDAlabelsPredictionl2=classifierl2.predict(LDATestProjection)\n",
        "\n",
        "classifierl3=KNeighborsClassifier(n_neighbors=5)\n",
        "classifierl3.fit(LDADataProjection,labels)\n",
        "LDAlabelsPredictionl3=classifierl3.predict(LDATestProjection)\n",
        "\n",
        "classifierl4=KNeighborsClassifier(n_neighbors=7)\n",
        "classifierl4.fit(LDADataProjection,labels)\n",
        "LDAlabelsPredictionl4=classifierl4.predict(LDATestProjection)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oICmtYS1hofW"
      },
      "source": [
        "Faces vs Non-Faces Accuracy Plot\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wk4yDO5Eh53T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "0b2256aa-ee9b-4494-da7d-19cf1e9a7f5d"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import precision_recall_fscore_support as score\n",
        "import numpy as np\n",
        "import cv2 \n",
        "import matplotlib as plt\n",
        "  \n",
        "\n",
        "def LdaProcess(nonFaceRange,traindata1,testdata1,labels):\n",
        "    traindata1 = traindata1.reshape(40*divider*multiplier,10304)\n",
        "    testdata1 = testdata1.reshape(40*(10-divider)*multiplier,10304)\n",
        "    labels=labels[0:0:200+nonFaceRange] \n",
        "    testdata1=testdata1[0:200+nonFaceRange]\n",
        "    meanMatrix=[]\n",
        "    instancematrix=[]\n",
        "    for i in range(0,200,1):\n",
        "      instancematrix.append(traindata1[i])\n",
        "        #print(np.shape(instancematrix))\n",
        "      #instancematrix=np.asarray(instancematrix)\n",
        "    temp=np.mean(instancematrix,axis = 0)\n",
        "    meanMatrix.append(temp)\n",
        "\n",
        "    instancematrix=[]\n",
        "    for i in range(200,200+nonFaceRange,1):\n",
        "      instancematrix.append(traindata1[i])\n",
        "        #print(np.shape(instancematrix))\n",
        "      #instancematrix=np.asarray(instancematrix)\n",
        "    temp=np.mean(instancematrix,axis = 0)\n",
        "    meanMatrix.append(temp)\n",
        "    overallMean = np.mean(traindata1,axis=0)\n",
        "    print('-------meanMatrix-------')  \n",
        "    print(np.shape(meanMatrix))\n",
        "    print(meanMatrix)\n",
        "    print('--------overallMean------')\n",
        "    print(np.shape(overallMean))\n",
        "    print(overallMean)\n",
        "    #between-class scatter matrix\n",
        "    meanMatrix = np.asarray(meanMatrix)\n",
        "    overallMean = np.asarray(overallMean)\n",
        "    meanMatrix = meanMatrix.reshape(2,10304,1)\n",
        "    overallMean = overallMean.reshape(10304,1)\n",
        "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
        "    print(np.shape(meanMatrix))\n",
        "    print(np.shape(overallMean))\n",
        "    print('%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%')\n",
        "    betweenClassScatter=np.zeros((10304,10304))\n",
        "    betweenClassScatter += 200*(np.dot((meanMatrix[0]-overallMean),(meanMatrix[0]-overallMean).transpose()))\n",
        "    betweenClassScatter += nonFaceRange*(np.dot((meanMatrix[1]-overallMean),(meanMatrix[1]-overallMean).transpose()))\n",
        "    print('--------')\n",
        "    print('between class scatter')\n",
        "    print(np.shape(betweenClassScatter))\n",
        "    print(betweenClassScatter)\n",
        "\n",
        "    print('finished')\n",
        "\n",
        "    withinClassScatter = np.zeros((10304,10304))\n",
        "    instancematrix=[]\n",
        "    for i in range(0,200,1):\n",
        "          instancematrix.append(traindata1[i])\n",
        "\n",
        "    x = meanMatrix[0].reshape(10304)\n",
        "    center = instancematrix-x\n",
        "    withinClassScatter+=np.dot((center).T,center)\n",
        "\n",
        "    instancematrix=[]\n",
        "    for i in range(200,200+nonFaceRange,1):\n",
        "          instancematrix.append(traindata1[i])\n",
        "\n",
        "    x = meanMatrix[1].reshape(10304)\n",
        "    center = instancematrix-x\n",
        "    withinClassScatter+=np.dot((center).T,center)\n",
        "\n",
        "\n",
        "    print(np.shape(withinClassScatter)) \n",
        "    print(withinClassScatter)\n",
        "    sInv = np.linalg.pinv(withinClassScatter)\n",
        "    eigenValuelda,eigenVectorlda = np.linalg.eigh(np.dot(sInv,betweenClassScatter))\n",
        "    print('this is the eigenvectors')\n",
        "    print(np.shape(eigenVectorlda))\n",
        "    print('this is the eigenvalue')\n",
        "    print(np.shape(eigenValuelda))\n",
        "\n",
        "\n",
        "    indexOfBiggestEigenvals = np.argsort(eigenValuelda)\n",
        "    print(np.shape(indexOfBiggestEigenvals))\n",
        "    listOfLda = []\n",
        "    for index in range(39):\n",
        "      listOfLda.append(eigenVectorlda[:,indexOfBiggestEigenvals[-index-1]])\n",
        "\n",
        "    LDADataProjection=np.dot(listOfLda,traindata1.T)\n",
        "    LDADataProjection=np.real(LDADataProjection.T)\n",
        "\n",
        "    LDATestProjection=np.dot(listOfLda,testdata1.T)\n",
        "    LDATestProjection=np.real(LDATestProjection.T)\n",
        "\n",
        "\n",
        "    classifier=KNeighborsClassifier(n_neighbors=1)\n",
        "    classifier.fit(LDADataProjection,labels)\n",
        "    LDAlabelsPrediction=classifier.predict(LDATestProjection)\n",
        "    precisionLDA,recallLDA,fscoreLDA,supportLDA=score(labels,LDAlabelsPrediction,average='macro')\n",
        "    return precisionLDA\n",
        "\n",
        "\n",
        "\n",
        "precision1=LdaProcess(200,traindata1,testdata1,labels)\n",
        "precision2=LdaProcess(150,traindata1,testdata1,labels)\n",
        "precision3=LdaProcess(100,traindata1,testdata1,labels)\n",
        "precision4=LdaProcess(50,traindata1,testdata1,labels)\n",
        "\n",
        "\n",
        "x = np.array([200,150,100,50])\n",
        "y = np.array([precision1,precision2,precision3,precision4])\n",
        "plt.scatter(x, y)\n",
        "plt.show()\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-923a4a371df8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m \u001b[0mprecision1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLdaProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraindata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestdata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0mprecision2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLdaProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraindata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestdata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0mprecision3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLdaProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraindata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtestdata1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'traindata1' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5UUjPTl1lYcf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}